---
title: "Practical Machine Learning Course Project"
author: "Nathan DeMaria"
date: "Friday, August 22, 2014"
output: html_document
---

# Data Setup

### Loading packages I will use
```{r packages}
suppressPackageStartupMessages(library(randomForest))
library(data.table)
suppressPackageStartupMessages(library(caret))
```

### Download the data
```{r download_data, cache = T}
download.file('http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv', destfile = 'train.csv')
download.file('http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv', destfile = 'test.csv')
```

### Load the data into data.tables
```{r load_data, cache=T}
train <- fread('train.csv')
test <- fread('test.csv')
```

### Train and Cross Validation Sets
First, I drop the columns from the data that won't be useful.  I chose to drop covariates that were either all empty or all NA (in the test data set).  I then randomly selected 1/4 of the training data to be used for cross validation.
```{r remove_extra}
# remove columns that aren't used in test set (they're for window summaries, or all NA)
relevant <- train[,c('roll_belt', 'pitch_belt', 'yaw_belt', 'total_accel_belt', 
													 'gyros_belt_x', 'gyros_belt_y', 'gyros_belt_z', 
													 'accel_belt_x', 'accel_belt_y', 'accel_belt_z', 
													 'magnet_belt_x', 'magnet_belt_y', 'magnet_belt_z', 
													 'roll_arm', 'pitch_arm', 'yaw_arm','total_accel_arm', 
													 'gyros_arm_x', 'gyros_arm_y', 'gyros_arm_z', 
													 'accel_arm_x', 'accel_arm_y', 'accel_arm_z', 
													 'magnet_arm_x', 'magnet_arm_y', 'magnet_arm_z', 
													 'roll_dumbbell', 'pitch_dumbbell', 'yaw_dumbbell',
													 'classe'),with=F]
relevant$classe <- factor(relevant$classe)

# places 75% in the training set, 25% in cross validation
set.seed(5477)
train_indices <- sample(1:dim(train)[1], dim(train)[1] * .75, replace = F)

train_relevant <- relevant[train_indices,]
cross_val <- relevant[-train_indices,]
```

### The Model
I chose to use a random forest to predict *classe*.
```{r the_forest, cache=T}
set.seed(18)
rf <- randomForest(classe ~ ., data = train_relevant)
rf
```

This gives 1.11% as the estimate for the out of bag error rate.

### Cross Validation
```{r cross_val}
cv_pred <- predict(rf, newdata=cross_val)
confusionMatrix(cv_pred, cross_val$classe)
```

Running the predictor on the above cross validation data set has an accuracy of .988, or an error rate of 1.2%.  This is close enough to the original estimate for the error rate that I will select this model to be used to predict on the test data set.


# Final Predictions
```{r final}
predictions <- predict(rf, newdata=test)
sapply(predictions, function(p) {
	write.table(p, col.names=F, row.names=F, quote=F, 
							file=paste0('predictions/prediction_', names(p), '.txt'))
	p
})
```

